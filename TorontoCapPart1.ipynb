import numpy as np
import requests
from bs4 import BeautifulSoup
import urllib.request
import pandas as pd

#Gets the url and scrapes the html 
url = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'
req = urllib.request.urlopen(url)

soup = BeautifulSoup(req)

#Finds the table to scrape
table = soup.find('table', class_='wikitable sortable')

#Provides the empty arrays for the html tags that are being grabbed and assigned to the headings
P = []
B = []
N = []

for row in table.find_all('tr'):
    cells = row.find_all('td')
    if len(cells) == 3:
        P.append(cells[0].find(text=True))
        B.append(cells[1].find(text=True))
        N.append(cells[2].find(text=True))
        
#Creates the dataframe and places the data in its respective columns
df = pd.DataFrame(P, columns=['PostalCode'])
df['Borough'] = B
df['Neighborhood'] = N
df

#Drops the 'Not assigned' Boroughs
na = df[df['Borough'] == 'Not assigned'].index
df.drop(na, inplace=True)

#A specialized function that joins the neighborhoods with the same postalcode
foo = lambda a: ','.join(a) 
df = df.groupby(['PostalCode', 'Borough']).agg({
                                'Neighborhood': foo}).reset_index()
                         
#Gets rid of the '\n' that was following some of my neighborhoods
df['Neighborhood'] = df['Neighborhood'].str.replace('\n','')

#Replaces neighborhoods that are 'Not assigned' with the corresponding Borough
df['Neighborhood'] = np.where(df['Neighborhood'] == 'Not assigned', df['Borough'], df['Neighborhood'])

df

df.shape
